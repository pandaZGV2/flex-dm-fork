{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f293d717",
   "metadata": {},
   "source": [
    "# RICO analysis\n",
    "This notebook qualitatively analyzes learned models in rico dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb8241e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1abd9f1a",
   "metadata": {},
   "source": [
    "##### Editable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63409a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"../rico/ours-exp-ft/checkpoints\"\n",
    "dataset_name = \"rico\"\n",
    "db_root = \"/scratch/aaron.monis/rico\"\n",
    "batch_size = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec3beb72",
   "metadata": {},
   "source": [
    "##### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ca99271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 16:06:30.703116: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import itertools\n",
    "import logging\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, HTML\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(\"../src/mfp\")\n",
    "\n",
    "from mfp.models.mfp import MFP, merge_inputs_and_prediction\n",
    "from mfp.models.architecture.mask import get_seq_mask\n",
    "from mfp.models.masking import get_initial_masks\n",
    "from mfp.data import DataSpec\n",
    "from mfp.helpers import svg_rico as svg\n",
    "from util import grouper, load_model\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# fix seed for debug\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20978d1b",
   "metadata": {},
   "source": [
    "##### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "034361e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:mask_value is deprecated, use mask_token instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:mask_value is deprecated, use mask_token instead.\n",
      "/home2/aaron.monis/.conda/envs/flexdm/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:2200: UserWarning: The `deterministic` argument has no effect unless the `num_parallel_calls` argument is specified.\n",
      "  warnings.warn(\"The `deterministic` argument has no effect unless the \"\n"
     ]
    }
   ],
   "source": [
    "dataspec = DataSpec(dataset_name, db_root, batch_size)\n",
    "test_dataset = dataspec.make_dataset(\"test\", shuffle=False)\n",
    "iterator = iter(test_dataset.take(1))\n",
    "example = next(iterator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f08c110f",
   "metadata": {},
   "source": [
    "##### Load pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efde3727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mfp.models.mfp:[('random', 1.0), ('elem', 0.0), ('type', 0.0), ('pos', 0.0), ('attr', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "input_columns = dataspec.make_input_columns()\n",
    "models = {\"main\": load_model(ckpt_dir, input_columns=input_columns)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9db7358",
   "metadata": {},
   "source": [
    "##### Define some helpers for ELEM-filling task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fcc5829",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder0 = svg.SVGBuilder(\n",
    "    max_width=128,\n",
    "    max_height=192,\n",
    "    key=\"type\",\n",
    "    preprocessor=dataspec.preprocessor,\n",
    ")\n",
    "\n",
    "# demo for ELEM prediction (randomly mask a single element)\n",
    "def visualize_reconstruction(models, example, dataspec, input_builders, output_builders):\n",
    "    seq_mask = get_seq_mask(example[\"length\"])\n",
    "    mfp_masks = get_initial_masks(input_columns, seq_mask)\n",
    "    example_copy = copy.deepcopy(example)\n",
    "\n",
    "    n_elem = tf.cast(tf.reduce_sum(tf.cast(seq_mask, tf.float32), axis=1), tf.int32).numpy()\n",
    "    target_indices = [random.randint(0, n - 1) for n in n_elem]\n",
    "    indices = []\n",
    "    B, S = example_copy[\"left\"].shape[:2]\n",
    "    for i in range(B):\n",
    "        indices.append([j for j in range(S) if j != target_indices[i]])\n",
    "    indices = tf.convert_to_tensor(np.array(indices))\n",
    "    for key in example_copy.keys():\n",
    "        if example_copy[key].shape[1] > 1:\n",
    "            example_copy[key] = tf.gather(example_copy[key], indices, batch_dims=1)\n",
    "    example_copy[\"length\"] -= 1\n",
    "\n",
    "    svgs = []\n",
    "    for builder in input_builders:\n",
    "        svgs.append(list(map(builder, dataspec.unbatch(example_copy))))\n",
    "\n",
    "    for key in mfp_masks.keys():\n",
    "        if not input_columns[key][\"is_sequence\"]:\n",
    "            continue\n",
    "        dummy = mfp_masks[key].numpy()\n",
    "        for i in range(len(target_indices)):\n",
    "            dummy[i, target_indices[i]] = True  # hide single element for each sample\n",
    "        mfp_masks[key] = tf.convert_to_tensor(dummy)\n",
    "\n",
    "    for model in models:\n",
    "        pred = model(example, training=False, demo_args={\"masks\": mfp_masks})\n",
    "        pred = merge_inputs_and_prediction(example, input_columns, mfp_masks, pred)\n",
    "\n",
    "        for builder in output_builders:\n",
    "            svgs.append(list(map(builder, dataspec.unbatch(pred))))\n",
    "\n",
    "    for builder in input_builders:\n",
    "        svgs.append(list(map(builder, dataspec.unbatch(example))))\n",
    "\n",
    "    return [list(grouper(row, len(input_builders))) for row in zip(*svgs)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "706181c4",
   "metadata": {},
   "source": [
    "##### Visualization of results\n",
    "From left to right: input (one element missing), prediction, ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c420788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 16:06:40.566362: E tensorflow/stream_executor/cuda/cuda_dnn.cc:389] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\n",
      "2023-05-20 16:06:40.566696: E tensorflow/stream_executor/cuda/cuda_dnn.cc:398] Possibly insufficient driver version: 515.48.7\n",
      "2023-05-20 16:06:40.566716: W ./tensorflow/stream_executor/stream.h:2104] attempting to perform DNN operation using StreamExecutor without DNN support\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Exception encountered when calling layer \"layer_normalization\" \"                 f\"(type LayerNormalization).\n\n{{function_node __wrapped__FusedBatchNormV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} cuDNN launch failure : input shape ([1,22,256,1]) [Op:FusedBatchNormV3]\n\nCall arguments received by layer \"layer_normalization\" \"                 f\"(type LayerNormalization):\n  • inputs=tf.Tensor(shape=(1, 22, 256), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m svgs \u001b[39m=\u001b[39m visualize_reconstruction(models\u001b[39m.\u001b[39;49mvalues(), example, dataspec, [builder0], [builder0])\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i, row \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(svgs):\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(i)\n",
      "Cell \u001b[0;32mIn[6], line 39\u001b[0m, in \u001b[0;36mvisualize_reconstruction\u001b[0;34m(models, example, dataspec, input_builders, output_builders)\u001b[0m\n\u001b[1;32m     36\u001b[0m     mfp_masks[key] \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(dummy)\n\u001b[1;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[0;32m---> 39\u001b[0m     pred \u001b[39m=\u001b[39m model(example, training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, demo_args\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mmasks\u001b[39;49m\u001b[39m\"\u001b[39;49m: mfp_masks})\n\u001b[1;32m     40\u001b[0m     pred \u001b[39m=\u001b[39m merge_inputs_and_prediction(example, input_columns, mfp_masks, pred)\n\u001b[1;32m     42\u001b[0m     \u001b[39mfor\u001b[39;00m builder \u001b[39min\u001b[39;00m output_builders:\n",
      "File \u001b[0;32m~/.conda/envs/flexdm/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/flex-dm/notebooks/../src/mfp/mfp/models/mfp.py:333\u001b[0m, in \u001b[0;36mMFP.call\u001b[0;34m(self, inputs, training, demo_args)\u001b[0m\n\u001b[1;32m    331\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(modified_inputs, targets, masks, training)\n\u001b[1;32m    332\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(modified_inputs, training)\n\u001b[1;32m    335\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_demo:\n\u001b[1;32m    336\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort_pos:\n",
      "File \u001b[0;32m~/flex-dm/notebooks/../src/mfp/mfp/models/model.py:28\u001b[0m, in \u001b[0;36m_OneShot.call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training):\n\u001b[1;32m     27\u001b[0m     h, mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(inputs, training\u001b[39m=\u001b[39mtraining)\n\u001b[0;32m---> 28\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks(h, mask, training\u001b[39m=\u001b[39;49mtraining)\n\u001b[1;32m     29\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(h, training\u001b[39m=\u001b[39mtraining)\n\u001b[1;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/flex-dm/notebooks/../src/mfp/mfp/models/architecture/transformer.py:279\u001b[0m, in \u001b[0;36mBlocks.__call__\u001b[0;34m(self, seq, mask, training)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseq2seq\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m--> 279\u001b[0m         seq \u001b[39m=\u001b[39m layer(seq, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n\u001b[1;32m    280\u001b[0m \u001b[39mreturn\u001b[39;00m seq\n",
      "File \u001b[0;32m~/flex-dm/notebooks/../src/mfp/mfp/models/architecture/transformer.py:216\u001b[0m, in \u001b[0;36mDeepSVGBlock.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     x \u001b[39m=\u001b[39m inputs\n\u001b[0;32m--> 216\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm1(x, training\u001b[39m=\u001b[39;49mtraining)\n\u001b[1;32m    217\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn(y, mask\u001b[39m=\u001b[39mmask)\n\u001b[1;32m    218\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(y, training\u001b[39m=\u001b[39mtraining)\n",
      "\u001b[0;31mInternalError\u001b[0m: Exception encountered when calling layer \"layer_normalization\" \"                 f\"(type LayerNormalization).\n\n{{function_node __wrapped__FusedBatchNormV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} cuDNN launch failure : input shape ([1,22,256,1]) [Op:FusedBatchNormV3]\n\nCall arguments received by layer \"layer_normalization\" \"                 f\"(type LayerNormalization):\n  • inputs=tf.Tensor(shape=(1, 22, 256), dtype=float32)"
     ]
    }
   ],
   "source": [
    "svgs = visualize_reconstruction(models.values(), example, dataspec, [builder0], [builder0])\n",
    "for i, row in enumerate(svgs):\n",
    "    print(i)\n",
    "    display(HTML(\"<div>%s</div>\" % \" \".join(itertools.chain.from_iterable(row))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b1cc4bcd870fb3eb296f14a2aa1daa467f3c14f214d3fd2c136db8d539a2d2c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
